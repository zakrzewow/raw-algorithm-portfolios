{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.configspace import (\n",
    "    COX_PH_CONFIGSPACE,\n",
    "    GB_COX_CONFIGSPACE,\n",
    "    GPR_CONFIGSPACE,\n",
    "    POLY_RIDGE_CONFIGSPACE,\n",
    "    RANDOM_FOREST_CONFIGSPACE,\n",
    "    RANDOM_SURVIVAL_FOREST_CONFIGSPACE,\n",
    "    RIDGE_CONFIGSPACE,\n",
    "    SCHMEE_HAHN_QRF_CONFIGSPACE,\n",
    "    SVR_CONFIGSPACE,\n",
    "    TOBIT_NN_CONFIGSPACE,\n",
    "    XGB_AFT_CONFIGSPACE,\n",
    "    XGB_CONFIGSPACE,\n",
    ")\n",
    "from src.constant import (\n",
    "    HO,\n",
    "    PROCESSED_DATA_DIR,\n",
    "    RANDOM_STATE_LIST,\n",
    "    RESULTS_0_10_DIR,\n",
    "    SOLVER_NUMBER_LIST,\n",
    ")\n",
    "from src.evaluation import evaluate_model_with_cross_validation\n",
    "from src.hyperparameter_optimization import optimize_hyperparameters\n",
    "from src.model import (\n",
    "    SVR,\n",
    "    CoxPHSurvivalAnalysis,\n",
    "    GPRWithRBF,\n",
    "    GradientBoostingSurvivalAnalysis,\n",
    "    PolynomialRidge,\n",
    "    RandomForestRegressor,\n",
    "    RandomSurvivalForest,\n",
    "    Ridge,\n",
    "    SchmeeHahnQRF,\n",
    "    TobitModel,\n",
    "    XGBRegressor,\n",
    "    XGBRegressorAFT,\n",
    ")\n",
    "from src.results import plot_line, plot_scatter, wilcoxon_df\n",
    "from src.split import get_n_splits\n",
    "from src.wrapper import (\n",
    "    ScikitLearnWrapper,\n",
    "    SkipCutOffScikitLearnWrapper,\n",
    "    StandardScaledLogTransformedWrapper,\n",
    "    SurvivalFunctionWrapper,\n",
    "    XGBwrapper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_df = pd.read_parquet(PROCESSED_DATA_DIR / \"evaluations.parquet\")\n",
    "solvers_df = pd.read_parquet(PROCESSED_DATA_DIR / \"solvers.parquet\")\n",
    "instances_df = pd.read_parquet(PROCESSED_DATA_DIR / \"instances.parquet\")\n",
    "\n",
    "df = pd.merge(evaluations_df, solvers_df, left_on=\"solver_id\", right_on=\"id\").drop(columns=[\"id\"])\n",
    "df = pd.merge(df, instances_df, left_on=\"instance_id\", right_on=\"id\").drop(columns=[\"id\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.instance.TSP_Instance import TSP_from_index_file, set_n22_cut_off_time\n",
    "# from src.constant import DATA_DIR\n",
    "# import json\n",
    "# train_instances = TSP_from_index_file(\n",
    "#     filepath=DATA_DIR / \"TSP\" / \"TRAIN\" / \"index.json\",\n",
    "# )\n",
    "# train_instances = set_n22_cut_off_time(train_instances, reference_cut_off_time=10.0)\n",
    "# instance_to_cut_off = {}\n",
    "# for instance in train_instances:\n",
    "#     key = instance._get_short_filepath()\n",
    "#     instance_to_cut_off[key] = instance.cut_off_time\n",
    "# with open(\"instance_to_cut_off.json\", \"w\") as f:\n",
    "#     json.dump(instance_to_cut_off, f, indent=4)\n",
    "\n",
    "import json\n",
    "with open(\"instance_to_cut_off.json\", \"r\") as f:\n",
    "    INSTANCE_TO_CUT_OFF = json.load(f)\n",
    "\n",
    "(df[\"cost\"] < df[\"instance_id\"].map(INSTANCE_TO_CUT_OFF)).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS = get_n_splits(\n",
    "    df=df,\n",
    "    n=HO.N,\n",
    "    instance_number=HO.INSTANCE_NUMBER,\n",
    "    solver_number=HO.SOLVER_NUMBER,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=Ridge,\n",
    "    wrapper_cls=ScikitLearnWrapper,\n",
    "    configspace=RIDGE_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"ridge_incumbent.pkl\",\n",
    ")\n",
    "\n",
    "ridge_incumbent_skip_cutoff = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=Ridge,\n",
    "    wrapper_cls=SkipCutOffScikitLearnWrapper,\n",
    "    configspace=RIDGE_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"ridge_incumbent_skip_cutoff.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PolynomialRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_ridge_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=PolynomialRidge,\n",
    "    wrapper_cls=ScikitLearnWrapper,\n",
    "    configspace=POLY_RIDGE_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"poly_ridge_incumbent.pkl\",\n",
    ")\n",
    "\n",
    "poly_ridge_incumbent_skip_cutoff = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=PolynomialRidge,\n",
    "    wrapper_cls=SkipCutOffScikitLearnWrapper,\n",
    "    configspace=POLY_RIDGE_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"poly_ridge_incumbent_skip_cutoff.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=RandomForestRegressor,\n",
    "    wrapper_cls=ScikitLearnWrapper,\n",
    "    configspace=RANDOM_FOREST_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"rf_incumbent.pkl\",\n",
    ")\n",
    "\n",
    "rf_incumbent_skip_cutoff = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=RandomForestRegressor,\n",
    "    wrapper_cls=SkipCutOffScikitLearnWrapper,\n",
    "    configspace=RANDOM_FOREST_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"rf_incumbent_skip_cutoff.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=XGBRegressor,\n",
    "    wrapper_cls=ScikitLearnWrapper,\n",
    "    configspace=XGB_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"xgb_incumbent.pkl\",\n",
    ")\n",
    "\n",
    "xgb_incumbent_skip_cutoff = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=XGBRegressor,\n",
    "    wrapper_cls=SkipCutOffScikitLearnWrapper,\n",
    "    configspace=XGB_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"xgb_incumbent_skip_cutoff.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=SVR,\n",
    "    wrapper_cls=ScikitLearnWrapper,\n",
    "    configspace=SVR_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"svr_incumbent.pkl\",\n",
    ")\n",
    "\n",
    "svr_incumbent_skip_cutoff = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=SVR,\n",
    "    wrapper_cls=SkipCutOffScikitLearnWrapper,\n",
    "    configspace=SVR_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"svr_incumbent_skip_cutoff.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPRWithRBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=GPRWithRBF,\n",
    "    wrapper_cls=ScikitLearnWrapper,\n",
    "    configspace=GPR_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"gpr_incumbent.pkl\",\n",
    ")\n",
    "\n",
    "gpr_incumbent_skip_cutoff = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=GPRWithRBF,\n",
    "    wrapper_cls=SkipCutOffScikitLearnWrapper,\n",
    "    configspace=GPR_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"gpr_incumbent_skip_cutoff.pkl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoxPHSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coxph_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=CoxPHSurvivalAnalysis,\n",
    "    wrapper_cls=SurvivalFunctionWrapper,\n",
    "    configspace=COX_PH_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"coxph_incumbent.pkl\",\n",
    ")\n",
    "coxph_incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSurvivalForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=RandomSurvivalForest,\n",
    "    wrapper_cls=SurvivalFunctionWrapper,\n",
    "    configspace=RANDOM_SURVIVAL_FOREST_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"rsf_incumbent.pkl\",\n",
    ")\n",
    "rsf_incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingSurvivalAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cox_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=GradientBoostingSurvivalAnalysis,\n",
    "    wrapper_cls=SurvivalFunctionWrapper,\n",
    "    configspace=GB_COX_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"gb_cox_incumbent.pkl\",\n",
    ")\n",
    "gb_cox_incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBRegressorAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_aft_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=XGBRegressorAFT,\n",
    "    wrapper_cls=XGBwrapper,\n",
    "    configspace=XGB_AFT_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"xgb_aft_incumbent.pkl\",\n",
    ")\n",
    "xgb_aft_incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SchmeeHahnQRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_qrf_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=SchmeeHahnQRF,\n",
    "    wrapper_cls=StandardScaledLogTransformedWrapper,\n",
    "    configspace=SCHMEE_HAHN_QRF_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"sh_qrf_incumbent.pkl\",\n",
    ")\n",
    "sh_qrf_incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TobitModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tobit_incumbent = optimize_hyperparameters(\n",
    "    df=df,\n",
    "    model_cls=TobitModel,\n",
    "    wrapper_cls=StandardScaledLogTransformedWrapper,\n",
    "    configspace=TOBIT_NN_CONFIGSPACE,\n",
    "    splits=SPLITS,\n",
    "    instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "    random_state=HO.RANDOM_STATE,\n",
    "    n_trials=HO.N_TRIALS,\n",
    "    filepath=RESULTS_0_10_DIR / \"HO\" / \"tobit_incumbent.pkl\",\n",
    ")\n",
    "tobit_incumbent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info_list = [\n",
    "    # include cut-off\n",
    "    {\n",
    "        \"wrapper\": ScikitLearnWrapper(**ridge_incumbent),\n",
    "        \"name\": \"Ridge Regression\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": ScikitLearnWrapper(**poly_ridge_incumbent),\n",
    "        \"name\": \"Polynomial Regression\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": ScikitLearnWrapper(**svr_incumbent),\n",
    "        \"name\": \"Support Vector Regression\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": ScikitLearnWrapper(**gpr_incumbent),\n",
    "        \"name\": \"Gaussian Process Regression\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": ScikitLearnWrapper(**rf_incumbent),\n",
    "        \"name\": \"Random Forest\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": ScikitLearnWrapper(**xgb_incumbent),\n",
    "        \"name\": \"XGBoost\"\n",
    "    },\n",
    "    # skip cut-off\n",
    "    {\n",
    "        \"wrapper\": SkipCutOffScikitLearnWrapper(**ridge_incumbent_skip_cutoff),\n",
    "        \"name\": \"Ridge Regression (skip cut-off)\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SkipCutOffScikitLearnWrapper(**poly_ridge_incumbent_skip_cutoff),\n",
    "        \"name\": \"Polynomial Regression (skip cut-off)\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SkipCutOffScikitLearnWrapper(**svr_incumbent_skip_cutoff),\n",
    "        \"name\": \"Support Vector Regression (skip cut-off)\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SkipCutOffScikitLearnWrapper(**gpr_incumbent_skip_cutoff),\n",
    "        \"name\": \"Gaussian Process Regression (skip cut-off)\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SkipCutOffScikitLearnWrapper(**rf_incumbent_skip_cutoff),\n",
    "        \"name\": \"Random Forest (skip cut-off)\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SkipCutOffScikitLearnWrapper(**xgb_incumbent_skip_cutoff),\n",
    "        \"name\": \"XGBoost (skip cut-off)\"\n",
    "    },\n",
    "    # survival models\n",
    "    {\n",
    "        \"wrapper\": SurvivalFunctionWrapper(**coxph_incumbent),\n",
    "        \"name\": \"Cox PH\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SurvivalFunctionWrapper(**rsf_incumbent),\n",
    "        \"name\": \"Random Survival Forest\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": SurvivalFunctionWrapper(**gb_cox_incumbent),\n",
    "        \"name\": \"Gradient Boosting Cox\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": XGBwrapper(**xgb_aft_incumbent),\n",
    "        \"name\": \"XGBoost AFT\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": StandardScaledLogTransformedWrapper(**sh_qrf_incumbent),\n",
    "        \"name\": \"S&H QRF\"\n",
    "    },\n",
    "    {\n",
    "        \"wrapper\": StandardScaledLogTransformedWrapper(**tobit_incumbent),\n",
    "        \"name\": \"NN Tobit\"\n",
    "    },\n",
    "]\n",
    " \n",
    "total_iterations = len(RANDOM_STATE_LIST) * len(SOLVER_NUMBER_LIST) * len(model_info_list)\n",
    "pbar = tqdm(total=total_iterations, desc=\"Evaluating models\")\n",
    "\n",
    "records = []\n",
    "\n",
    "for random_state in RANDOM_STATE_LIST:\n",
    "    for solver_number in SOLVER_NUMBER_LIST:\n",
    "        pbar.set_description(f\"RS={random_state}, Solvers={solver_number}\")\n",
    "        splits = get_n_splits(\n",
    "            df,\n",
    "            n=5,\n",
    "            instance_number=10,\n",
    "            solver_number=solver_number,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        for model_info in model_info_list:\n",
    "            pbar.set_postfix(model=model_info[\"name\"])\n",
    "\n",
    "            result = evaluate_model_with_cross_validation(\n",
    "                df,\n",
    "                wrapper=model_info[\"wrapper\"],\n",
    "                splits=splits,\n",
    "                random_state=random_state,\n",
    "                instance_to_cut_off=INSTANCE_TO_CUT_OFF,\n",
    "            )\n",
    "            result[\"random_state\"] = random_state\n",
    "            result[\"solver_number\"] = solver_number\n",
    "            result[\"name\"] = model_info[\"name\"]\n",
    "            records.append(result)\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "result_df = pd.DataFrame(records)\n",
    "result_df.to_pickle(RESULTS_0_10_DIR / \"results.gzip\", compression=\"gzip\")\n",
    "\n",
    "result_df = pd.read_pickle(RESULTS_0_10_DIR / \"results.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = result_df.loc[(result_df[\"random_state\"] == 1) & (result_df[\"solver_number\"] == 300)].iloc[[0, 1, 2, 3, 4, 5, 12, 13, 14, 15, 16, 17]].reset_index(drop=True)\n",
    "\n",
    "fig, axs = plot_scatter(plot_df)\n",
    "# plt.savefig(\"fig.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = result_df.loc[(result_df[\"random_state\"] == 1) & (result_df[\"solver_number\"] == 300)].iloc[[0, 1, 2, 3, 4, 5, 12, 13, 14, 15, 16, 17]].reset_index(drop=True)\n",
    "plot_df.loc[:5, \"name\"] += \" (i)\"\n",
    "const_cut_off = None\n",
    "\n",
    "n_plots = len(plot_df)\n",
    "n_cols = 3\n",
    "n_rows = (n_plots + n_cols - 1) // n_cols\n",
    "fig, axs = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(9, 2.9 * n_rows))\n",
    "\n",
    "if n_rows == 1:\n",
    "    axs = axs.reshape(1, -1)\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, result in plot_df.iterrows():\n",
    "    ax = axs[i]\n",
    "\n",
    "    ax.scatter(\n",
    "        result[\"y_test_not_censored\"],\n",
    "        result[\"y_pred\"],\n",
    "        alpha=0.5,\n",
    "        edgecolors=\"k\",\n",
    "        lw=0.2,\n",
    "        s=3,\n",
    "    )\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    ax.set_xlim(0.01, 320)\n",
    "    ax.set_ylim(0.01, 320)\n",
    "    ax.plot([0.01, 300], [0.01, 300], \"k--\", alpha=0.75, zorder=0)\n",
    "    ax.set_title(f'{result[\"name\"]} (RMSE={result[\"rmse\"]:.2f})', fontsize=10)\n",
    "    if const_cut_off is not None:\n",
    "        ax.axhline(y=const_cut_off, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "for i in range(n_plots, len(axs)):\n",
    "    axs[i].set_visible(False)\n",
    "\n",
    "for row in range(n_rows):\n",
    "    left_idx = row * n_cols\n",
    "    if left_idx < n_plots:\n",
    "        axs[left_idx].set_ylabel(\"Predicted Runtime\")\n",
    "\n",
    "bottom_row_start = (n_rows - 1) * n_cols\n",
    "for col in range(n_cols):\n",
    "    bottom_idx = bottom_row_start + col\n",
    "    if bottom_idx < n_plots:\n",
    "        axs[bottom_idx].set_xlabel(\"Actual Runtime\")\n",
    "\n",
    "plt.tight_layout(h_pad=2, w_pad=2)\n",
    "plt.savefig(\"fig.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_line(\n",
    "    result_df.loc[\n",
    "        result_df[\"name\"].isin(\n",
    "            [\n",
    "                \"Cox PH\",\n",
    "                \"Random Survival Forest\",\n",
    "                \"Gradient Boosting Cox\",\n",
    "                \"XGBoost AFT\",\n",
    "                \"S&H QRF\",\n",
    "                \"NN Tobit\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# plt.savefig(\"fig.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = result_df.loc[\n",
    "    result_df[\"name\"].isin(\n",
    "        [\n",
    "            \"Cox PH\",\n",
    "            \"Random Survival Forest\",\n",
    "            \"Gradient Boosting Cox\",\n",
    "            \"XGBoost AFT\",\n",
    "            \"S&H QRF\",\n",
    "            \"NN Tobit\",\n",
    "        ]\n",
    "    )\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 3))\n",
    "\n",
    "# Get unique solver numbers and model names\n",
    "solver_numbers = sorted(plot_df[\"solver_number\"].unique())\n",
    "model_names = plot_df[\"name\"].unique()\n",
    "\n",
    "# Create positions for boxplots\n",
    "n_models = len(model_names)\n",
    "width = 4\n",
    "positions = []\n",
    "labels = []\n",
    "\n",
    "for i, solver_num in enumerate(solver_numbers):\n",
    "    for j, model_name in enumerate(model_names):\n",
    "        pos = i * (n_models + 1) + j\n",
    "        positions.append(pos)\n",
    "        \n",
    "        # Get data for this model and solver number\n",
    "        data = plot_df[(plot_df[\"solver_number\"] == solver_num) & \n",
    "                      (plot_df[\"name\"] == model_name)][\"rmse\"].values\n",
    "        \n",
    "        # Create boxplot\n",
    "        bp = plt.boxplot(data, positions=[pos], widths=width/n_models, \n",
    "                patch_artist=True, manage_ticks=False, showfliers=False)\n",
    "        \n",
    "        # Color the boxplot based on model\n",
    "        colors = plt.cm.tab10(j)\n",
    "        bp['boxes'][0].set_facecolor(colors)\n",
    "        \n",
    "        # Set edge width\n",
    "        for element in ['boxes', 'whiskers', 'fliers', 'caps']:\n",
    "            if element in bp:\n",
    "                for item in bp[element]:\n",
    "                    item.set_linewidth(0.66)\n",
    "        \n",
    "        # Set median line width and color it to match box (to hide it)\n",
    "        bp['medians'][0].set_linewidth(0.66)\n",
    "        bp['medians'][0].set_color('black')\n",
    "\n",
    "# Set x-axis labels\n",
    "x_positions = [i * (n_models + 1) + (n_models - 1) / 2 for i in range(len(solver_numbers))]\n",
    "plt.xticks(x_positions, solver_numbers)\n",
    "\n",
    "# Create legend\n",
    "handles = [plt.Rectangle((0,0),1,1, facecolor=plt.cm.tab10(i), alpha=1.0) \n",
    "          for i in range(n_models)]\n",
    "plt.legend(handles, model_names, loc=\"best\", frameon=True, fontsize=9)\n",
    "\n",
    "plt.xlabel(\"Number of algorithm configurations in the training set\")\n",
    "plt.ylabel(\"RMSE (on logarithmized predictions)\")\n",
    "plt.tight_layout()\n",
    "# plt.title(\"RMSE vs. the number of algorithm configurations in the training set\")\n",
    "plt.savefig(\"0_10_boxplot.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_result = wilcoxon_df(result_df, model_info_list)\n",
    "styled_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_result.to_excel(\"tmp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [x[\"name\"] for x in model_info_list]\n",
    "# fit time\n",
    "result_df.pivot_table(index=\"name\", columns=\"solver_number\", values=\"fit_time\", aggfunc=\"mean\").loc[idx].style.background_gradient(cmap=\"coolwarm\", axis=None).format(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict time\n",
    "result_df.pivot_table(index=\"name\", columns=\"solver_number\", values=\"predict_time\", aggfunc=\"mean\").loc[idx].style.background_gradient(cmap=\"coolwarm\", axis=None).format(precision=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
